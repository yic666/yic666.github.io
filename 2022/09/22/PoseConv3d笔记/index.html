<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Revisiting Skeleton-based Action Recognition 论文：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2104.13586 代码：https:&#x2F;&#x2F;github.com&#x2F;kennymckormick&#x2F;pyskl 摘要与结论 尽管许多基于GCN的骨架动作识别算法取得不错的结果，但依旧在鲁棒性、互操作性和可扩展性方面存在限制。  提出了PoseConv3D：一种以3">
<meta property="og:type" content="article">
<meta property="og:title" content="PoseConv3d笔记">
<meta property="og:url" content="http://example.com/2022/09/22/PoseConv3d%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Yic">
<meta property="og:description" content="Revisiting Skeleton-based Action Recognition 论文：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2104.13586 代码：https:&#x2F;&#x2F;github.com&#x2F;kennymckormick&#x2F;pyskl 摘要与结论 尽管许多基于GCN的骨架动作识别算法取得不错的结果，但依旧在鲁棒性、互操作性和可扩展性方面存在限制。  提出了PoseConv3D：一种以3">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923200807607.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923201902224.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923204038409.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923210128369.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923210416469.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923211126851.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924200056400.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924164508040.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924183705271.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924195658960.png">
<meta property="article:published_time" content="2022-09-22T08:48:46.000Z">
<meta property="article:modified_time" content="2022-09-26T11:16:33.124Z">
<meta property="article:author" content="Yic-gdut">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="行为识别">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923200807607.png">


<link rel="canonical" href="http://example.com/2022/09/22/PoseConv3d%E7%AC%94%E8%AE%B0/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/09/22/PoseConv3d%E7%AC%94%E8%AE%B0/","path":"2022/09/22/PoseConv3d笔记/","title":"PoseConv3d笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PoseConv3d笔记 | Yic</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Yic</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81%E4%B8%8E%E7%BB%93%E8%AE%BA"><span class="nav-number">1.</span> <span class="nav-text">摘要与结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%95%E8%A8%80"><span class="nav-number">2.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A7%BF%E6%80%81%E6%8F%90%E5%8F%96%E7%9A%84%E8%89%AF%E5%A5%BD%E5%AE%9E%E8%B7%B5"><span class="nav-number">3.1.</span> <span class="nav-text">姿态提取的良好实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="nav-number">3.1.1.</span> <span class="nav-text">消融实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2D-v-s-3D-%E9%AA%A8%E6%9E%B6"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">2D v.s. 3D 骨架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bottom-Up-v-s-Top-Down"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">Bottom-Up v.s. Top-Down.</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Interested-Person-v-s-All-Persons"><span class="nav-number">3.1.1.3.</span> <span class="nav-text">Interested Person v.s. All Persons.</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Coordinates-v-s-Heatmaps"><span class="nav-number">3.1.1.4.</span> <span class="nav-text">Coordinates v.s. Heatmaps</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E2D%E5%A7%BF%E5%8A%BF%E7%94%9F%E6%88%903D%E7%83%AD%E5%9B%BE"><span class="nav-number">3.2.</span> <span class="nav-text">从2D姿势生成3D热图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8%E4%BA%8E%E5%9F%BA%E4%BA%8E%E9%AA%A8%E6%9E%B6%E7%9A%84%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E7%9A%843D-CNN"><span class="nav-number">3.3.</span> <span class="nav-text">用于基于骨架的动作识别的3D-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PoseConv3D"><span class="nav-number">3.3.1.</span> <span class="nav-text">PoseConv3D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RGBPose-Conv3D"><span class="nav-number">3.3.2.</span> <span class="nav-text">RGBPose-Conv3D</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yic-gdut</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/22/PoseConv3d%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yic-gdut">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yic">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="PoseConv3d笔记 | Yic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PoseConv3d笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-22 16:48:46" itemprop="dateCreated datePublished" datetime="2022-09-22T16:48:46+08:00">2022-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-09-26 19:16:33" itemprop="dateModified" datetime="2022-09-26T19:16:33+08:00">2022-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" itemprop="url" rel="index"><span itemprop="name">视频理解</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>Revisiting Skeleton-based Action Recognition</p>
<p>论文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.13586">https://arxiv.org/abs/2104.13586</a></p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/kennymckormick/pyskl">https://github.com/kennymckormick/pyskl</a></p>
<h1 id="摘要与结论"><a href="#摘要与结论" class="headerlink" title="摘要与结论"></a>摘要与结论</h1><ul>
<li><p>尽管许多基于GCN的骨架动作识别算法取得不错的结果，但依旧在鲁棒性、互操作性和可扩展性方面存在限制。</p>
</li>
<li><p>提出了PoseConv3D：一种以3D热图体积作为输入的基于3D-CNN的骨骼动作识别方法，与GCN的方法相比</p>
<ul>
<li>在学习时空特征方面更加有效</li>
<li>对姿态估计的噪声更具有鲁棒性</li>
<li>在交叉数据集中更具有泛化性</li>
<li>在处理多人场景方面无需额外计算成本</li>
</ul>
</li>
<li><p>另外，更容易与其他模态结合，在八个多模态识别基准达到了SOTA</p>
</li>
</ul>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>基于人体骨架的动作识别其动作聚焦性和紧凑性，近年来受到越来越多的关注。在实践中，视频中的人体骨架主要表示为一系列的关节坐标列表，其中的坐标由姿态估计器提取。GCN是最受欢迎的方法之一，具体地说，GCN将每个时间步长的每个人体关节视为一个节点，空间和时间维度上的相邻节点通过边连接起来，然后将图卷积层应用于所构建的图，以发现跨空间和时间的动作模式。</p>
<p>基于GCN的方法在以下方面有局限性:</p>
<ul>
<li>鲁棒性：由于GCN直接处理关节坐标，坐标上的微小扰动通常导致完全不同的预测。</li>
<li>互操作性：由于GCN是在骨架图上操作的，因此难以与其他模态结合。</li>
<li>可扩展性：由于GCN将每个人体关节视为节点，因此涉及多人的场景中复杂性线性上升。</li>
</ul>
<p>本文提出了PoseConv3D，解决了GCN方法的局限性：</p>
<ul>
<li>使用3D热图表示骨架对姿态估计更具有鲁棒性，对不同方法获得的输入挂架具有很好的泛化能力</li>
<li>依赖于热图表示，更容易与其他模态集成到多流网络</li>
<li>热图表示的复杂度与人数无关，处理多人场景不会增加计算开销</li>
</ul>
<h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><h2 id="姿态提取的良好实践"><a href="#姿态提取的良好实践" class="headerlink" title="姿态提取的良好实践"></a>姿态提取的良好实践</h2><p>人体骨骼或姿态提取是基于骨骼的动作识别的重要预处理步骤，对最终的识别精度有很大影响。</p>
<p>一般来说2D姿势比3D姿势效果更好，如下图。与自底向上的方法相比，自顶向下的方法在标准基准(如coco -关键点)上获得了优越的性能。</p>
<p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923200807607.png" alt="image-20220923200807607"></p>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p>作者设计了一系列采用的不同的替代方法的姿态提取的消融实验。以下的3D-CNN实验的输入均为$T<em>H</em>W&#x3D;48<em>56</em>56$</p>
<h4 id="2D-v-s-3D-骨架"><a href="#2D-v-s-3D-骨架" class="headerlink" title="2D v.s. 3D 骨架"></a>2D v.s. 3D 骨架</h4><p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923201902224.png" alt="image-20220923201902224"></p>
<p>使用MS-G3D（用于基于骨骼的动作识别的当前最先进的GCN），对2D和3D关键点具有相同的配置和训练计划，结果如上表。</p>
<p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923204038409.png" alt="image-20220923204038409"></p>
<p>除了基于rgb的3d位姿估计方法，还考虑了“提升”方法，直接“提升”2d姿势(序列)到3d姿势(序列)，基于HRNet提取的2D姿态对3D姿态进行回归，利用提升后的3D姿态进行动作识别。上表的结果表明，这种被提升的3D姿势没有提供任何额外的信息，在动作识别方面的表现甚至比原始的2D姿势更差。</p>
<h4 id="Bottom-Up-v-s-Top-Down"><a href="#Bottom-Up-v-s-Top-Down" class="headerlink" title="Bottom-Up v.s. Top-Down."></a>Bottom-Up v.s. Top-Down.</h4><p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923210128369.png"></p>
<p>作者用相同的主干实例化这两种方法(HRNet-w32)。此外，作者还用MobileNet-v2骨干网实例化自顶向下方法进行比较，它在coco验证方面的性能与HRNet(自底向上)相似。上表的结果显示，HRNet(自下而上)在COCO-val上的性能远低于HRNet(自顶向下)，接近于MobileNet(自顶向下)。</p>
<h4 id="Interested-Person-v-s-All-Persons"><a href="#Interested-Person-v-s-All-Persons" class="headerlink" title="Interested Person v.s. All Persons."></a>Interested Person v.s. All Persons.</h4><p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923210416469.png" alt="image-20220923210416469"></p>
<p>很多人可能存在于一个视频中，但并不是所有人都与感兴趣的动作有关。作者使用3种人物边界框进行姿态提取：Detection，Tracking（使用Siamese-RPN)和GT(对运动员的关注增加)。从上表的结果可以得到当事人的先验是极其重要的，即使是较弱的先验知识(每个视频1 个GT box)也能大大提高性能。</p>
<h4 id="Coordinates-v-s-Heatmaps"><a href="#Coordinates-v-s-Heatmaps" class="headerlink" title="Coordinates v.s. Heatmaps"></a>Coordinates v.s. Heatmaps</h4><p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220923211126851.png" alt="image-20220923211126851"></p>
<p>存储3D热图可能会占用大量磁盘空间。为提升效率，将每个 2D 关键点存储为坐标 (x, y, score)，其中 score 为预测的置信度。在 FineGYM 上进行了实验，以估计这种热图 → 坐标的压缩会带来多大信息损失。作者发现，在使用高质量特征提取器的情况下，使用坐标作为输入，动作识别的精度仅有少量下降 (0.4%)。因此在后续工作中，作者以坐标的格式来存储提取出的 2D 姿态。</p>
<h2 id="从2D姿势生成3D热图"><a href="#从2D姿势生成3D热图" class="headerlink" title="从2D姿势生成3D热图"></a>从2D姿势生成3D热图</h2><p>论文用大小为$K<em>H</em>W$的热图来表示二维姿势,其中K是关节点的数量，H和W是框架的高度和宽度。如果只有coordinate-triplets$(x_k; y_k; c_k)$,可以通过组合以每个关节为中心的K个高斯映射来得到一个关节热图J:</p>
<p>$\boldsymbol{J}<em>{k i j}&#x3D;e^{-\frac{\left(i-x</em>{k}\right)^{2}+\left(j-y_{k}\right)^{2}}{2 * \sigma^{2}}} * c_{k}$</p>
<p>其中$\sigma$控制高斯映射的方差，$(x_k, y_k)$和$c_k$分别是第k个关节的位置和置信度分数，还可以创建limb热图：</p>
<p>$\boldsymbol{L}<em>{k i j}&#x3D;e^{-\frac{\mathcal{D}\left((i, j), s e g\left[a</em>{k}, b_{k}\right]\right)^{2}}{2 * \sigma^{2}}} * \min \left(c_{a_{k}}, c_{b_{k}}\right)$</p>
<p>第k个limb是在两个关节$a_k$和$b_k$之间。函数D计算从点$(i,J)$到段$\left[\left(x_{a_{k}}, y_{a_{k}}\right),\left(x_{b_{k}}, y_{b_{k}}\right)\right]$的距离。值得注意的是，尽管上述过程假设每一帧中都有一个人，但可以很容易地将其扩展到多人的情况，在这里直接累积所有人的第k个高斯映射，而无需放大热图。最后，一个3D热图堆叠是通过将所有热图($J$或$L$)沿时间维度堆叠而得到的，因此形状会是$K \times T \times H \times W$</p>
<p>实际应用中，作者使用了两种方法来尽可能减少 3D 热图堆叠中的冗余，使其更紧凑</p>
<ol>
<li>Subjects-Centered Cropping</li>
</ol>
<p>使热图与帧一样大是低效的，特别是当相关人员只在一个小区域活动时。在这种情况，先找到能够囊括了所有的2D姿势的边界框，然后根据找到的框裁剪所有帧，并将它们调整为目标大小。这样的话，2D姿势以及它们的移动能被保存，且使得三维热图体积的大小可以在空间上缩小。</p>
<ol start="2">
<li>Uniform Sampling.</li>
</ol>
<p>通过对帧的子集进行采样，还可以沿时间维减小3D热图的体积。具体来说，为从视频中采样n帧，将视频分成n个等长的片段，并从每个片段中随机选择一帧。</p>
<p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924200056400.png" alt="image-20220924200056400"></p>
<h2 id="用于基于骨架的动作识别的3D-CNN"><a href="#用于基于骨架的动作识别的3D-CNN" class="headerlink" title="用于基于骨架的动作识别的3D-CNN"></a>用于基于骨架的动作识别的3D-CNN</h2><h3 id="PoseConv3D"><a href="#PoseConv3D" class="headerlink" title="PoseConv3D"></a>PoseConv3D</h3><p>PoseConv3D以3D热图堆叠作为输入，可以用各种3D- cnn的backbone实例化。与一般的3D-CNN网络相比，需要添加两个修改：（1）由于3D热图体积的空间分辨率不需要像RGB剪辑那么大，因此在3D- cnn中删除了早期阶段的下采样操作；（2）由于采用的3D热图已经是中级特征，因此一个更浅(更少层)和更薄(更少通道)的网络对于PoseConv3D已经足够了。基于这些改动，作者采用了三种著名的3D-CNN：C3D，SlowOnly和X3D</p>
<p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924164508040.png" alt="image-20220924164508040"></p>
<p>如下表所示，采用轻量级版本的3d - cnn可以显著降低计算复杂度，但识别性能略有下降。而SlowOnly直接从Resnet膨胀而来而且具有良好的识别性能，作者将其作为Backbone。</p>
<p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924183705271.png" alt="image-20220924183705271"></p>
<h3 id="RGBPose-Conv3D"><a href="#RGBPose-Conv3D" class="headerlink" title="RGBPose-Conv3D"></a>RGBPose-Conv3D</h3><p>作者提出RGBPose-Conv3D用于早期的人体骨骼和RGB帧的融合，有两条通路分别处理RGB模态和Pose模态。总的来说，RGBPose-Conv3D的架构遵循几个原则：（1）相比于RGB流，Pose流具有较小的通道宽度和较小的深度，以及更小的输入空间分辨率；（2）加了Early Fusion，增加了两个通路之间的双向横向连接，促进两种模式之间的早期特征融合。RGBPose- Conv3D分别使用每个通路的两个单独损失进行训练，因为联合从两种模态学习的单个损失会导致严重的过拟合。</p>
<p><img src="https://raw.githubusercontent.com/yic666/Blogimg/master/image-20220924195658960.png" alt="image-20220924195658960"></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag"># 笔记</a>
              <a href="/tags/%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB/" rel="tag"># 行为识别</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/09/12/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/" rel="prev" title="视频理解相关论文">
                  <i class="fa fa-chevron-left"></i> 视频理解相关论文
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/18/%E3%80%8ADynamic-Spatio-Temporal-Specialization-Learning-for-Fine-Grained-Action-Recognition%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" rel="next" title="《Dynamic Spatio-Temporal Specialization Learning for Fine-Grained Action Recognition》阅读笔记">
                  《Dynamic Spatio-Temporal Specialization Learning for Fine-Grained Action Recognition》阅读笔记 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yic-gdut</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
