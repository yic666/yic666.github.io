<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="SVFormer: Semi-supervised Video Transformer for Action Recognition paper：http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.13222 code：https:&#x2F;&#x2F;github.com&#x2F;ChenHsing&#x2F;SVFormer 摘要 半监督动作识别是一项具有挑战性但又至关重要的任务，因为视频注释的成本很高。现有方法主要使">
<meta property="og:type" content="article">
<meta property="og:title" content="SVFormer: Semi-supervised Video Transformer for Action Recognition">
<meta property="og:url" content="http://example.com/2023/06/28/SVFormer-Semi-supervised-Video-Transformer-for-Action-Recognition/index.html">
<meta property="og:site_name" content="Yic">
<meta property="og:description" content="SVFormer: Semi-supervised Video Transformer for Action Recognition paper：http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.13222 code：https:&#x2F;&#x2F;github.com&#x2F;ChenHsing&#x2F;SVFormer 摘要 半监督动作识别是一项具有挑战性但又至关重要的任务，因为视频注释的成本很高。现有方法主要使">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-06-28T01:24:39.000Z">
<meta property="article:modified_time" content="2023-07-18T05:04:17.203Z">
<meta property="article:author" content="Yic-gdut">
<meta property="article:tag" content="论文笔记">
<meta property="article:tag" content="动作识别">
<meta property="article:tag" content="CVPR2023">
<meta property="article:tag" content="Transformer-based">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2023/06/28/SVFormer-Semi-supervised-Video-Transformer-for-Action-Recognition/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/06/28/SVFormer-Semi-supervised-Video-Transformer-for-Action-Recognition/","path":"2023/06/28/SVFormer-Semi-supervised-Video-Transformer-for-Action-Recognition/","title":"SVFormer: Semi-supervised Video Transformer for Action Recognition"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>SVFormer: Semi-supervised Video Transformer for Action Recognition | Yic</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Yic</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%95%E8%A8%80"><span class="nav-number">2.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ssl%E8%AE%BE%E7%BD%AE"><span class="nav-number">3.1.</span> <span class="nav-text">SSL设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pipeline"><span class="nav-number">3.2.</span> <span class="nav-text">Pipeline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tube-tokenmix"><span class="nav-number">3.3.</span> <span class="nav-text">Tube TokenMix</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91mixing"><span class="nav-number">3.3.1.</span> <span class="nav-text">视频Mixing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%B6%E9%97%B4%E6%89%AD%E6%9B%B2%E5%A2%9E%E5%BC%BA-temporal-warping-augmentation"><span class="nav-number">3.3.2.</span> <span class="nav-text">时间扭曲增强
Temporal Warping Augmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.4.</span> <span class="nav-text">训练模式</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yic-gdut</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/28/SVFormer-Semi-supervised-Video-Transformer-for-Action-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yic-gdut">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yic">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="SVFormer: Semi-supervised Video Transformer for Action Recognition | Yic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SVFormer: Semi-supervised Video Transformer for Action Recognition
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-28 09:24:39" itemprop="dateCreated datePublished" datetime="2023-06-28T09:24:39+08:00">2023-06-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-07-18 13:04:17" itemprop="dateModified" datetime="2023-07-18T13:04:17+08:00">2023-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" itemprop="url" rel="index"><span itemprop="name">视频理解</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>SVFormer: Semi-supervised Video Transformer for Action
Recognition</p>
<p>paper：http://arxiv.org/abs/2211.13222</p>
<p>code：https://github.com/ChenHsing/SVFormer</p>
<h1 id="摘要">摘要</h1>
<p>半监督动作识别是一项具有挑战性但又至关重要的任务，因为视频注释的成本很高。现有方法主要使用卷积神经网络，然而当前的革命性视觉Transformer模型尚未得到充分探索。在本文中，我们研究了在半监督学习（SSL）设置下使用Transformer模型进行动作识别的方法。为此，我们引入了SVFormer，它采用了稳定的伪标签框架（即EMATeacher）来处理无标签视频样本。虽然广泛的数据增强方法已被证明对于半监督图像分类是有效的，但对于视频识别而言，它们通常产生有限的结果。因此，我们引入了一种针对视频数据的新型增强策略，称为Tube
Token-Mix，其中视频剪辑通过掩码和一致的遮蔽标记在时间轴上混合。此外，我们提出了一种时域扭曲增强方法，用于覆盖视频中复杂的时域变化，它将选定的帧在剪辑中拉伸到不同的时间长度。对三个数据集Kinetics-400、UCF-101和HMDB-51进行了大量实验证实了SVFormer的优势。特别是，在Kinetics-400的1%标注率下，SVFormer在较少的训练周期内比现有技术提升了31.5%。我们的方法有望作为一个强有力的基准，并鼓励未来在使用Transformer网络进行半监督动作识别方面的研究。</p>
<h1 id="引言">引言</h1>
<p>论文背景：目前，视频在互联网上逐渐取代了图像和文字，并以指数级的速度增长。有监督的视频理解已经取得了巨大的成功，但这些工作依赖于大规模手工标注，因此利用现成的无标签视频来更好地理解视频是非常重要的。</p>
<p>过去方案：半监督方法通常基于伪标签的模式，通常是用已标记数据来预训练网络，然后利用预训练的模型为未标记的数据生成伪标签，最后使用伪标签进一步改进预训练模型。学界通常采用额外模态（比如光流）或者辅助网络的方式提高伪标签的质量，但这类方法会带来额外的训练或推理成本。</p>
<p>论文的Motivation：鉴于TransFormer架构在视频领域的巨大成功，而原有的SSL方法（如Mixup和CutMix）并不适用于TransFormer架构，本文旨在提出一种基于TransFormer的半监督动作识别方法，并提出一种适用于TransFormer架构的增强方法，能够更好地对token之间的时间相关性进行建模。另外，本文还提出一种时间扭曲增强方法可以覆盖视频中复杂的时间变化。</p>
<p>论文的Contribution：</p>
<ol type="1">
<li>率先探索了半监督视频识别的变压器模型。</li>
<li>提出了一种token级增强方法Tube
Token-Mix，它比像素级混合策略更适合视频Transformer。</li>
<li>在三个基准数据集上进行了广泛的实验，达到了SOTA。</li>
</ol>
<p><img
src="https://yic-123.oss-cn-guangzhou.aliyuncs.com//img/20230628113047.png" /></p>
<h1 id="方法">方法</h1>
<h2 id="ssl设置">SSL设置</h2>
<p>假设我们有N个训练视频样本，包括N_L个带有标签的视频样本<span
class="math inline">\((x_l,y_l) \in \mathcal{D}_L\)</span>和<span
class="math inline">\(N_U\)</span>个无标签的视频样本<span
class="math inline">\(x_u \in \mathcal{D}_U\)</span>，其中<span
class="math inline">\(x_l\)</span>是带有类别标签<span
class="math inline">\(y_l\)</span>的标记视频样本，<span
class="math inline">\(x_u\)</span>是无标签的视频样本。通常情况下，<span
class="math inline">\(N_U \gg N_L\)</span>。半监督学习的目标是利用<span
class="math inline">\(\mathcal{D}_L\)</span>和<span
class="math inline">\(\mathcal{D}_U\)</span>来训练模型。</p>
<h2 id="pipeline">Pipeline</h2>
<p>SVFormer采用了流行的半监督学习框架FixMatch，该框架利用两个不同增强视图之间的一致性损失。训练范式分为两个部分。</p>
<p>对于标记集合<span class="math inline">\(\{(x_l,
y_l)\}_{l=1}^{N_L}\)</span>，模型优化有监督损失<span
class="math inline">\({\cal{L}}_{s}\)</span>： $$ <span
class="math display">\[\begin{equation}

{\cal{L}}_{s}=\frac{1}{N_L}\sum_{}^{N_L}{\cal{H}}({\cal{F}}
({x_l}),y_l),
\end{equation}\]</span> $$ 其中<span
class="math inline">\({\cal{F}}(\cdot)\)</span>表示模型产生的预测，<span
class="math inline">\({\cal{H}}\)</span>是标准的交叉熵损失函数。</p>
<p>对于无标签样本<span
class="math inline">\(x_u\)</span>，我们首先使用弱增强（例如，随机水平翻转、随机缩放和随机裁剪）和强增强（例如，AutoAugment或Dropout）分别生成两个视图，<span
class="math inline">\(x_w={\cal{A}}_{weak}(x_u)\)</span>，<span
class="math inline">\(x_s={\cal{A}}_{strong}(x_u)\)</span>。然后，利用模型生成的弱视图的伪标签<span
class="math inline">\({\hat{y}_w}=\arg\max({\cal{F}}(x_w))\)</span>来监督强视图，使用以下无监督损失：
<span class="math display">\[
\begin{equation}
{\cal{L}}_{un}=\frac{1}{N_U}\sum^{N_U}{\mathbb{I}} (\max({\cal{F}}(x_w))
&gt; \delta){\cal{H}}({\cal{F}}({x_s}),\hat{y}_w),
\end{equation}
\]</span> 其中<span
class="math inline">\(\delta\)</span>是预定义的阈值，<span
class="math inline">\({\mathbb{I}}\)</span>是指示函数，当最大类别概率超过<span
class="math inline">\(\delta\)</span>时，它的值为1，否则为0。置信度指标用于过滤嘈杂的伪标签。</p>
<p>在FixMatch中，两个增强的输入共享同一个模型，这容易导致模型容易崩溃
。因此，论文采用了指数移动平均（EMA）-Teacher，这是FixMatch的改进版本。
伪标签是由EMA-Teacher模型生成的，该模型的参数通过对学生参数进行指数移动平均来更新，具体表示为：
<span class="math display">\[
\begin{equation}
{\theta}_t \gets m {\theta}_t +(1- m) {\theta}_s,
\end{equation}
\]</span> 其中<span
class="math inline">\(m\)</span>是一个动量系数，<span
class="math inline">\(\theta_{t}\)</span>和<span
class="math inline">\(\theta_{s}\)</span>分别是教师模型和学生模型的参数。</p>
<h2 id="tube-tokenmix">Tube TokenMix</h2>
<p>在半监督框架中，一个核心问题是如何使用高质量的伪标签丰富数据集。
Mixup
是一种广泛采用的数据增强策略，它通过以下方式在样本和标签之间执行凸组合：
<span class="math display">\[
\begin{equation}
  \hat{x} = \lambda \cdot x_1 + (1-\lambda) \cdot x_2,
\end{equation}
\]</span> <span class="math display">\[
\begin{equation}
  \hat{y} = \lambda \cdot y_1 + (1-\lambda) \cdot y_2,
\end{equation}
\]</span> 其中比例 <span class="math inline">\(\lambda\)</span>
是一个符合贝塔分布的标量。Mixup及其变种（例如CutMix）在低数据情况下的许多任务中取得了成功，例如长尾分类、域自适应、少样本学习等等。对于半监督学习，Mixup
通过在图像分类中混合无标签样本的伪标签也表现良好。</p>
<h3 id="视频mixing">视频Mixing</h3>
<p>对于基于TransFormer的方法，原本像素级的mixing增强方法（Mixup
或CutMix）并不适用于token级的模型。因此论文提出三种用于视频数据的mixing增强方法：Rand
TokenMix、Frame TokenMix和Tube TokenMix。</p>
<figure>
<img
src="https://yic-123.oss-cn-guangzhou.aliyuncs.com//img/20230629104912.png"
alt="Tube TokenMix训练框架" />
<figcaption aria-hidden="true">Tube TokenMix训练框架</figcaption>
</figure>
<p>给定未标记的视频片段<span class="math inline">\(x_a, x_b\in
\mathbb{R}^{H\times W\times T}\)</span>，使用一个基于标记的掩码<span
class="math inline">\(\textbf{M}\in\{0,1\}^{H\times W\times
T}\)</span>来执行样本混合。这里<span
class="math inline">\(H\)</span>和<span
class="math inline">\(W\)</span>分别表示经过分块标记化后的帧的高度和宽度，<span
class="math inline">\(T\)</span>表示片段长度。为了生成一个新的样本<span
class="math inline">\(x_{mix}\)</span>，在进行强数据增强<span
class="math inline">\({\cal{A}}_{strong}\)</span>后，按照以下方式混合<span
class="math inline">\(x_a\)</span>和<span
class="math inline">\(x_b\)</span>： <span class="math display">\[
\begin{equation}
    x_{mix} = {\cal{A}}_{strong}(x_a) \odot \textbf{M} +
{\cal{A}}_{strong}(x_b) \odot (\textbf{1}-\textbf{M}),
\end{equation}
\]</span> 其中<span
class="math inline">\(\odot\)</span>表示逐元素相乘，<span
class="math inline">\(\textbf{1}\)</span>是一个全为1的二值掩码。</p>
<figure>
<img
src="https://yic-123.oss-cn-guangzhou.aliyuncs.com//img/20230706152632.png"
alt="Masks增强例子" />
<figcaption aria-hidden="true">Masks增强例子</figcaption>
</figure>
<p>在三种增强方法中，掩码<span
class="math inline">\(\textbf{M}\)</span>的处理方式不同，如图所示。
对于Rand TokenMix，被掩盖的标记是从整个视频剪辑中（<span
class="math inline">\(H\times W\times T\)</span>个标记）随机选择的。
对于Frame TokenMix，从<span
class="math inline">\(T\)</span>个帧中随机选择一些帧，并将这些帧中的所有标记进行掩盖。
对于Tube
TokenMix，采用了管道式的掩盖策略，即不同帧共享相同的空间掩码矩阵。在这种情况下，掩码<span
class="math inline">\(\textbf{M}\)</span>在时间轴上具有一致的掩盖标记。</p>
<p>利用上述的增强方法可以掩码混合两个片段并合成一个新的混合数据样本，然后，混合样本<span
class="math inline">\(x_{mix}\)</span>被馈送到学生模型<span
class="math inline">\({\cal{F}}_{s}\)</span>，得到模型预测<span
class="math inline">\(y_{mix} = {\cal{F}}_{s}(x_{mix})\)</span>。
此外，通过将弱增强样本<span
class="math inline">\({\cal{A}}_{weak}(x_a)\)</span>和<span
class="math inline">\({\cal{A}}_{weak}(x_b)\)</span>输入到教师模型<span
class="math inline">\({\cal{F}}_{t}\)</span>中，产生<span
class="math inline">\(x_a\)</span>和<span
class="math inline">\(x_b\)</span>的伪标签<span
class="math inline">\(\hat{y}_a,\hat{y}_b\)</span>： <span
class="math display">\[
\begin{equation}
    \hat{y}_a = \arg\max({\cal{F}}_{t}({\cal{A}}_{weak}(x_a))),
\end{equation}
\]</span> <span class="math display">\[
\begin{equation}
    \hat{y}_b = \arg\max({\cal{F}}_{t}({\cal{A}}_{weak}(x_b))).   
\end{equation}
\]</span> 注意，如果<span
class="math inline">\(\max({\cal{F}}_{t}({\cal{A}}_{weak}(x)))&lt;\delta\)</span>，则伪标签<span
class="math inline">\(\hat{y}\)</span>保持软标签<span
class="math inline">\({\cal{F}}_{t}({\cal{A}}_{weak}(x))\)</span>不变。
对于<span class="math inline">\(x_{mix}\)</span>，伪标签<span
class="math inline">\(\hat{y}_{mix}\)</span>通过使用掩码比例<span
class="math inline">\(\lambda\)</span>混合<span
class="math inline">\(\hat{y}_a\)</span>和<span
class="math inline">\(\hat{y}_b\)</span>生成： <span
class="math display">\[
\begin{equation}
    \hat{y}_{mix} = \lambda \cdot \hat{y}_a + (1-\lambda) \cdot
\hat{y}_b.
\end{equation}
\]</span> 最后，学生模型通过以下一致性损失进行优化： $$ <span
class="math display">\[\begin{equation}

    {\cal{L}}_{mix}= \frac{1}{N_{m}} \sum^{N_{m}}(\hat{y}_{mix} -
y_{mix})^2,
\end{equation}\]</span> $$ 其中<span
class="math inline">\(N_{m}\)</span>是混合样本的数量。
TTMix的一致性损失算法显示在算法:Consistency loss for Tube
TokenMix中。</p>
<figure>
<img
src="https://yic-123.oss-cn-guangzhou.aliyuncs.com//img/20230706153406.png"
alt="Consistency loss for Tube TokenMix" />
<figcaption aria-hidden="true">Consistency loss for Tube
TokenMix</figcaption>
</figure>
<h3 id="时间扭曲增强-temporal-warping-augmentation">时间扭曲增强
Temporal Warping Augmentation</h3>
<p>作者提出扭曲每个帧的时间持续性，从而将更高的随机性引入数据中。时间扭曲增强（TWAug）可以将一个帧的时间长度拉伸到各种不同的值。
给定一个包含<span
class="math inline">\(T\)</span>帧（例如，8帧）的提取视频片段，随机决定保留所有帧，或者选择一小部分帧（例如，2或4帧），并遮盖其他帧。
然后，被遮盖的帧会用随机的相邻可见（未遮盖）帧进行填充。
请注意，在进行时间填充后，帧的顺序仍然保持不变。
下图分别显示了选择2、4和8帧的三个示例。
提出的TWAug可以帮助模型在训练过程中学习灵活的时间动态。</p>
<figure>
<img
src="https://yic-123.oss-cn-guangzhou.aliyuncs.com//img/20230706160835.png"
alt="时间扭曲增强" />
<figcaption aria-hidden="true">时间扭曲增强</figcaption>
</figure>
<figure>
<img
src="https://yic-123.oss-cn-guangzhou.aliyuncs.com//img/20230706161103.png"
alt="TTMix中使用时间扭曲增强和空间增强示例" />
<figcaption
aria-hidden="true">TTMix中使用时间扭曲增强和空间增强示例</figcaption>
</figure>
<h2 id="训练模式">训练模式</h2>
<p>SVFormer的训练由三个部分组成：由式（1）给出的有监督损失、由式（2）给出的无监督伪标签一致性损失以及由式（10）给出的TTMix一致性损失。最终的损失函数如下所示：
<span class="math display">\[
\begin{equation}
{\cal{L}}_{all}= {\cal{L}}_{s} + {\gamma}_1  {\cal{L}}_{un} +
{\gamma}_2  {\cal{L}}_{mix},
\end{equation}
\]</span> 其中<span class="math inline">\({\gamma}_1\)</span>和<span
class="math inline">\({\gamma}_2\)</span>是平衡损失项的超参数。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" rel="tag"># 论文笔记</a>
              <a href="/tags/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB/" rel="tag"># 动作识别</a>
              <a href="/tags/CVPR2023/" rel="tag"># CVPR2023</a>
              <a href="/tags/Transformer-based/" rel="tag"># Transformer-based</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/06/26/Video-Test-Time-Adaptation-for-Action-Recognition/" rel="prev" title="Video Test-Time Adaptation for Action Recognition">
                  <i class="fa fa-chevron-left"></i> Video Test-Time Adaptation for Action Recognition
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/07/18/3Mformer/" rel="next" title="3Mformer">
                  3Mformer <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yic-gdut</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
